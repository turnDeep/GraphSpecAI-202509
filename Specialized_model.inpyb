# GraphSpecAI: 特化型モデルのトレーニングとクラスタリング

このノートブックでは、分子クラスタリングを行い、特定のターゲット分子に特化したGNNモデルを作成します。

## 1. 環境設定とライブラリのインポート

```python
import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, random_split
from torch_geometric.nn import GATv2Conv, GCNConv, GlobalAttention, global_mean_pool, global_add_pool, global_max_pool
from torch_geometric.data import Data, Batch
from sklearn.model_selection import train_test_split
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
from rdkit import Chem
from rdkit.Chem import AllChem, Descriptors, MACCSkeys, Draw
from rdkit.Chem.Draw import IPythonConsole
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
import seaborn as sns
from tqdm.notebook import tqdm
import logging
import copy
import random
import math
import json
from torch.optim.lr_scheduler import OneCycleLR, LambdaLR, ReduceLROnPlateau

# Jupyter内でのロガー設定
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# パス設定 - 環境に合わせて変更してください
DATA_PATH = "data/"
MOL_FILES_PATH = os.path.join(DATA_PATH, "mol_files/")
MSP_FILE_PATH = os.path.join(DATA_PATH, "NIST17.MSP")

# 保存先ディレクトリの作成
os.makedirs("results", exist_ok=True)
os.makedirs("models", exist_ok=True)
os.makedirs("plots", exist_ok=True)
```

## 2. 定数と設定値の定義

```python
# 原子の特徴マッピング
ATOM_FEATURES = {
    'C': 0, 'N': 1, 'O': 2, 'S': 3, 'F': 4, 'Cl': 5, 'Br': 6, 'I': 7, 'P': 8,
    'Si': 9, 'B': 10, 'Na': 11, 'K': 12, 'Li': 13, 'Mg': 14, 'Ca': 15, 'Fe': 16,
    'Co': 17, 'Ni': 18, 'Cu': 19, 'Zn': 20, 'H': 21, 'OTHER': 22
}

# 結合の特徴マッピング
BOND_FEATURES = {
    Chem.rdchem.BondType.SINGLE: 0,
    Chem.rdchem.BondType.DOUBLE: 1,
    Chem.rdchem.BondType.TRIPLE: 2,
    Chem.rdchem.BondType.AROMATIC: 3
}

# 最大m/z値の設定
MAX_MZ = 2000

# フラグメントパターンの数（MACCSキー使用）
NUM_FRAGS = 167  # MACCSキーのビット数

# 特徴的なm/z値のリスト (よく現れるフラグメントイオンに対応)
IMPORTANT_MZ = [18, 28, 43, 57, 71, 73, 77, 91, 105, 115, 128, 152, 165, 178, 207]

# モデルのハイパーパラメータ
HIDDEN_CHANNELS = 256
BATCH_SIZE = 64
NUM_EPOCHS = 100
LEARNING_RATE = 0.001
```

## 3. 損失関数とユーティリティ関数の定義

```python
def cosine_similarity_score(y_true, y_pred, important_mz=IMPORTANT_MZ):
    """コサイン類似度を計算する（改良版）"""
    y_true_flat = y_true.reshape(y_true.shape[0], -1)
    y_pred_flat = y_pred.reshape(y_pred.shape[0], -1)
    
    # 各サンプルにおいて、値の高い上位Kのピークのみを考慮
    K = 200  # 上位K個のピークを考慮
    
    scores = []
    for i in range(y_true_flat.shape[0]):
        true_vec = y_true_flat[i]
        pred_vec = y_pred_flat[i]
        
        # ゼロ除算を避ける
        if np.sum(true_vec) == 0 or np.sum(pred_vec) == 0:
            scores.append(0)
            continue
            
        # 重要なm/z値を強調
        true_weighted = true_vec.copy()
        pred_weighted = pred_vec.copy()
        
        for mz in important_mz:
            if mz < len(true_vec):
                true_weighted[mz] *= 2.0
                pred_weighted[mz] *= 2.0
            
        # 上位Kピークのインデックスを取得
        top_k_true = np.argsort(true_weighted)[-K:]
        top_k_pred = np.argsort(pred_weighted)[-K:]
        
        # 上位ピークの和集合を取得
        important_indices = np.union1d(top_k_true, top_k_pred)
        
        # 重要なインデックスのみでコサイン類似度を計算
        true_vec_filtered = true_weighted[important_indices]
        pred_vec_filtered = pred_weighted[important_indices]
        
        # ゼロベクターチェック
        if np.sum(true_vec_filtered) == 0 or np.sum(pred_vec_filtered) == 0:
            similarity = 0
        else:
            similarity = cosine_similarity(
                true_vec_filtered.reshape(1, -1), 
                pred_vec_filtered.reshape(1, -1)
            )[0][0]
            
        scores.append(similarity)
    
    return np.mean(scores)

def combined_loss(y_pred, y_true, fragment_pred=None, fragment_true=None, alpha=0.2):
    """MSEとコサイン類似度損失の組み合わせ（マルチタスク対応）"""
    # バッチサイズの確認
    if y_pred.shape[0] != y_true.shape[0]:
        # バッチサイズが異なる場合、最小のバッチサイズに合わせる
        min_batch_size = min(y_pred.shape[0], y_true.shape[0])
        y_pred = y_pred[:min_batch_size]
        y_true = y_true[:min_batch_size]
        print(f"バッチサイズ調整後: y_pred={y_pred.shape}, y_true={y_true.shape}")
    
    # 特徴数の確認
    if y_pred.shape[1] != y_true.shape[1]:
        min_size = min(y_pred.shape[1], y_true.shape[1])
        y_pred = y_pred[:, :min_size]
        y_true = y_true[:, :min_size]
        print(f"特徴数調整後: y_pred={y_pred.shape}, y_true={y_true.shape}")
    
    # スペクトル予測の損失
    # ピーク重視MSE損失
    peak_mask = (y_true > 0).float()
    mse_weights = peak_mask * 10.0 + 1.0
    mse_loss = torch.mean(mse_weights * (y_pred - y_true) ** 2)
    
    # コサイン類似度損失
    y_pred_norm = F.normalize(y_pred, p=2, dim=1)
    y_true_norm = F.normalize(y_true, p=2, dim=1)
    cosine = torch.sum(y_pred_norm * y_true_norm, dim=1)
    cosine_loss = 1.0 - cosine
    
    # 主要な損失関数の組み合わせ（コサイン類似度を重視）
    main_loss = alpha * mse_loss + (1 - alpha) * cosine_loss.mean()
    
    # フラグメントパターン予測がある場合
    if fragment_pred is not None and fragment_true is not None:
        # バッチサイズの確認
        if fragment_pred.shape[0] != fragment_true.shape[0]:
            min_batch_size = min(fragment_pred.shape[0], fragment_true.shape[0])
            fragment_pred = fragment_pred[:min_batch_size]
            fragment_true = fragment_true[:min_batch_size]
        
        fragment_loss = F.binary_cross_entropy_with_logits(fragment_pred, fragment_true)
        # マルチタスク損失（スペクトル予測を主、フラグメント予測を副タスクとする）
        return main_loss + 0.2 * fragment_loss
    
    return main_loss

def collate_fn(batch):
    """バッチ内のグラフデータとマススペクトルを結合する"""
    graphs, spectra, fragments = zip(*batch)
    batched_graphs = Batch.from_data_list(list(graphs))
    batched_spectra = torch.stack(spectra)
    batched_fragments = torch.stack(fragments)
    return batched_graphs, batched_spectra, batched_fragments
```

## 4. モデルクラスの定義

```python
class SqueezeExcitation(nn.Module):
    """Squeeze-and-Excitation ブロック"""
    def __init__(self, channel, reduction=16):
        super(SqueezeExcitation, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool1d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, max(channel // reduction, 8), bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(max(channel // reduction, 8), channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c = x.size()
        y = self.avg_pool(x.unsqueeze(-1)).view(b, c)
        y = self.fc(y).view(b, c, 1)
        return x * y.squeeze(-1)

class ResidualBlock(nn.Module):
    """残差ブロック（バッチ正規化付き）"""
    def __init__(self, in_channels, out_channels):
        super(ResidualBlock, self).__init__()
        self.conv1 = nn.Linear(in_channels, out_channels)
        self.bn1 = nn.BatchNorm1d(out_channels)
        self.conv2 = nn.Linear(out_channels, out_channels)
        self.bn2 = nn.BatchNorm1d(out_channels)
        
        # 入力と出力のチャネル数が異なる場合の調整用レイヤー
        self.shortcut = nn.Sequential()
        if in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Linear(in_channels, out_channels),
                nn.BatchNorm1d(out_channels)
            )
            
        # Squeeze-and-Excitation
        self.se = SqueezeExcitation(out_channels)
        
        # ドロップアウト
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x):
        residual = self.shortcut(x)
        
        out = F.leaky_relu(self.bn1(self.conv1(x)))
        out = self.dropout(out)
        out = self.bn2(self.conv2(out))
        
        # SE適用
        out = self.se(out)
        
        out += residual  # 残差接続
        out = F.leaky_relu(out)
        
        return out

class AttentionBlock(nn.Module):
    """拡張グローバルアテンションブロック"""
    def __init__(self, in_dim, hidden_dim, heads=4):
        super(AttentionBlock, self).__init__()
        self.heads = heads
        self.head_dim = hidden_dim // heads
        
        # マルチヘッドアテンション
        self.query = nn.Linear(in_dim, hidden_dim)
        self.key = nn.Linear(in_dim, hidden_dim)
        self.value = nn.Linear(in_dim, hidden_dim)
        
        self.attn_combine = nn.Linear(hidden_dim, hidden_dim)
        
        # ゲート付きグローバルアテンション
        self.gate_nn = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.LeakyReLU(),
            nn.Linear(hidden_dim, 1)
        )
        
        self.message_nn = nn.Sequential(
            nn.Linear(in_dim, hidden_dim),
            nn.LeakyReLU(),
            nn.Linear(hidden_dim, in_dim)
        )
        
        # 出力投影
        self.out_proj = nn.Linear(hidden_dim + in_dim, in_dim)
        self.layer_norm = nn.LayerNorm(in_dim)
        self.dropout = nn.Dropout(0.1)
        
    def forward(self, x, batch):
        batch_size = torch.max(batch).item() + 1
        device = x.device
        
        # マルチヘッドアテンション計算
        q = self.query(x).view(-1, self.heads, self.head_dim)
        k = self.key(x).view(-1, self.heads, self.head_dim)
        v = self.value(x).view(-1, self.heads, self.head_dim)
        
        # バッチごとにアテンション計算
        attn_outputs = []
        
        for b in range(batch_size):
            mask = (batch == b)
            if not mask.any():
                continue
                
            q_b = q[mask]
            k_b = k[mask]
            v_b = v[mask]
            
            # スケーリングドットプロダクトアテンション
            attention = torch.bmm(q_b, k_b.transpose(1, 2)) / (self.head_dim ** 0.5)
            attention = F.softmax(attention, dim=2)
            
            # アテンション適用
            context = torch.bmm(attention, v_b)
            context = context.reshape(context.size(0), -1)
            context = self.attn_combine(context)
            
            attn_outputs.append(context)
        
        # アテンション出力の結合
        if attn_outputs:
            attn_out = torch.cat(attn_outputs, dim=0)
        else:
            attn_out = torch.zeros(x.size(0), self.heads * self.head_dim, device=device)
        
        # GlobalAttentionの計算
        global_attn = GlobalAttention(self.gate_nn, self.message_nn)(x, batch)
        
        # 結合と残差接続
        combined = torch.cat([attn_out, global_attn], dim=1)
        out = self.out_proj(combined)
        out = self.layer_norm(out + global_attn)  # 残差接続
        out = self.dropout(out)
        
        return out

class HybridGNNModel(nn.Module):
    """ハイブリッドGNN + CNN + Transformerモデル（コサイン類似度0.9目標）"""
    def __init__(self, node_features, edge_features, hidden_channels, out_channels, num_fragments=NUM_FRAGS):
        super(HybridGNNModel, self).__init__()
        
        # エッジの実際の次元を計算
        edge_dim = edge_features
        print(f"エッジ特徴量の次元: {edge_dim}")
        
        # グローバル特徴量の次元を設定 - グラフ単位の特徴量次元は16
        self.global_features_dim = 16  # 1分子あたりの特徴量次元
        print(f"グローバル特徴量の次元: {self.global_features_dim}")
        
        # グラフアテンション層（マルチヘッド）
        self.conv1 = GATv2Conv(node_features, hidden_channels, edge_dim=edge_dim, heads=4)
        self.conv2 = GATv2Conv(hidden_channels*4, hidden_channels, edge_dim=edge_dim, heads=4)
        self.conv3 = GATv2Conv(hidden_channels*4, hidden_channels, edge_dim=edge_dim, heads=4)
        self.conv4 = GATv2Conv(hidden_channels*4, hidden_channels, edge_dim=edge_dim, heads=4)
        self.conv5 = GATv2Conv(hidden_channels*4, hidden_channels, edge_dim=edge_dim, heads=2)
        
        # スキップ接続
        self.skip_connection1 = nn.Linear(hidden_channels*4, hidden_channels*4)
        self.skip_connection2 = nn.Linear(hidden_channels*4, hidden_channels*4)
        
        # グローバルアテンション
        self.global_attention = AttentionBlock(hidden_channels*2, hidden_channels, heads=4)
        
        # グローバル特徴量処理
        self.global_proj = nn.Sequential(
            nn.Linear(self.global_features_dim, hidden_channels*2),
            nn.LeakyReLU(),
            nn.LayerNorm(hidden_channels*2)
        )
        
        # スペクトル予測のための全結合層
        self.fc_layers = nn.ModuleList([
            ResidualBlock(hidden_channels*2 + hidden_channels*2, hidden_channels*4),
            ResidualBlock(hidden_channels*4, hidden_channels*4),
            ResidualBlock(hidden_channels*4, hidden_channels*4),
            ResidualBlock(hidden_channels*4, hidden_channels*2)
        ])
        
        # マルチタスク学習: フラグメントパターン予測
        self.fragment_pred = nn.Sequential(
            nn.Linear(hidden_channels*2, hidden_channels),
            nn.LeakyReLU(),
            nn.Dropout(0.3),
            nn.Linear(hidden_channels, num_fragments),
        )
        
        # 最終出力層（スペクトル予測）
        self.output_layer = nn.Sequential(
            nn.Linear(hidden_channels*2, hidden_channels),
            nn.LeakyReLU(),
            nn.Linear(hidden_channels, MAX_MZ)
        )
        
        # 活性化関数とドロップアウト
        self.act = nn.LeakyReLU()
        self.dropout = nn.Dropout(0.3)
        
        # バッチ正規化
        self.bn1 = nn.BatchNorm1d(hidden_channels*4)
        self.bn2 = nn.BatchNorm1d(hidden_channels*4)
        self.bn3 = nn.BatchNorm1d(hidden_channels*4)
        self.bn4 = nn.BatchNorm1d(hidden_channels*2)
        
        # レイヤー正規化
        self.ln1 = nn.LayerNorm(hidden_channels*4)
        
        # 重み初期化
        self._init_weights()
    
    def _init_weights(self):
        """重みの初期化（収束を高速化）"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm1d) or isinstance(m, nn.LayerNorm):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)
    
    def forward(self, data):
        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch
        global_attr = data.global_attr
        
        # グローバル属性のリシェイプとバッチサイズ調整 - バッチサイズに対応
        if len(global_attr.shape) == 1:  # [batch_size*features] -> [batch_size, features]
            num_graphs = batch[-1].item() + 1  # バッチ内のグラフ数
            features_per_graph = global_attr.shape[0] // num_graphs
            
            # グローバル属性をバッチサイズに合わせてリシェイプ
            if features_per_graph == self.global_features_dim:
                # 正常なケース: 各グラフが16次元の特徴を持つ
                global_attr = global_attr.view(num_graphs, self.global_features_dim)
            else:
                # 異常なケース: 特徴量の次元が期待と異なる
                # 特徴量をゼロパディングして対応
                print(f"Warning: グローバル特徴量の次元が予期せぬ値です: {features_per_graph}")
                global_attr_padded = torch.zeros(num_graphs, self.global_features_dim, device=global_attr.device)
                # 利用可能な特徴量をコピー
                for i in range(num_graphs):
                    start_idx = i * features_per_graph
                    end_idx = min(start_idx + features_per_graph, global_attr.shape[0])
                    copy_size = min(features_per_graph, self.global_features_dim)
                    global_attr_padded[i, :copy_size] = global_attr[start_idx:start_idx+copy_size]
                global_attr = global_attr_padded
        
        # グラフコンボリューション層
        x1 = self.act(self.conv1(x, edge_index, edge_attr))
        x1 = self.dropout(x1)
        
        x2 = self.act(self.conv2(x1, edge_index, edge_attr))
        x2 = self.dropout(x2)
        
        # スキップ接続1
        x1_transformed = self.skip_connection1(x1)
        x2 = x2 + x1_transformed
        x2 = self.ln1(x2)
        
        x3 = self.act(self.conv3(x2, edge_index, edge_attr))
        x3 = self.dropout(x3)
        
        x4 = self.act(self.conv4(x3, edge_index, edge_attr))
        x4 = self.dropout(x4)
        
        # スキップ接続2
        x2_transformed = self.skip_connection2(x2)
        x4 = x4 + x2_transformed
        
        x5 = self.act(self.conv5(x4, edge_index, edge_attr))
        
        # グローバルプーリングを使用してノード特徴量をグラフ単位に集約
        x_graph = global_mean_pool(x5, batch)
        
        # グローバル特徴量の処理
        global_features = self.global_proj(global_attr)
        
        # 特徴量の結合
        x_combined = torch.cat([x_graph, global_features], dim=1)
        
        # 残差ブロックを通した特徴抽出
        for i, fc_layer in enumerate(self.fc_layers):
            x_combined = fc_layer(x_combined)
            if i < len(self.fc_layers) - 1:
                x_combined = self.dropout(x_combined)
        
        # マルチタスク学習: フラグメントパターン予測
        fragment_pred = self.fragment_pred(x_combined)
        
        # スペクトル予測
        output = self.output_layer(x_combined)
        
        # 出力次元が合わない場合は調整する
        if output.shape[1] != MAX_MZ:
            print(f"警告: 出力サイズを {output.shape[1]} から {MAX_MZ} に調整します")
            new_output = torch.zeros(output.shape[0], MAX_MZ, device=output.device)
            min_size = min(output.shape[1], MAX_MZ)
            new_output[:, :min_size] = output[:, :min_size]
            output = new_output
        
        # 出力の正規化（非負制約）
        output = F.relu(output)
        
        return output, fragment_pred
```

## 5. データセットクラスの定義

```python
class MoleculeGraphDataset(Dataset):
    def __init__(self, mol_ids, mol_files_path, msp_data, augment=False):
        self.mol_ids = mol_ids
        self.mol_files_path = mol_files_path
        self.msp_data = msp_data
        self.augment = augment
        self.valid_mol_ids = []  # 有効な分子IDを保存するリスト
        self.fragment_patterns = {}  # 分子IDごとのフラグメントパターン
        
        # 前処理で有効な分子IDを抽出
        self._preprocess_mol_ids()
        
    def _preprocess_mol_ids(self):
        """有効な分子IDのみを抽出する"""
        valid_ids = []
        fragment_patterns = {}
        
        for mol_id in tqdm(self.mol_ids, desc="Validating molecules"):
            mol_file = os.path.join(self.mol_files_path, f"ID{mol_id}.MOL")
            try:
                # 分子ファイルが読み込めるか確認
                mol = Chem.MolFromMolFile(mol_file, sanitize=False)
                if mol is None:
                    continue
                
                # 分子の基本的なサニタイズを試みる
                try:
                    # プロパティキャッシュを更新
                    for atom in mol.GetAtoms():
                        atom.UpdatePropertyCache(strict=False)
                    
                    # 部分的なサニタイズ
                    Chem.SanitizeMol(mol, 
                                   sanitizeOps=Chem.SanitizeFlags.SANITIZE_FINDRADICALS|
                                              Chem.SanitizeFlags.SANITIZE_KEKULIZE|
                                              Chem.SanitizeFlags.SANITIZE_SETAROMATICITY|
                                              Chem.SanitizeFlags.SANITIZE_SETCONJUGATION|
                                              Chem.SanitizeFlags.SANITIZE_SETHYBRIDIZATION|
                                              Chem.SanitizeFlags.SANITIZE_SYMMRINGS,
                                   catchErrors=True)
                except Exception as e:
                    continue
                
                # グラフに変換できるか確認
                try:
                    _ = self._mol_to_graph(mol_file)
                    valid_ids.append(mol_id)
                    
                    # フラグメントパターンを生成（マルチタスク学習用）
                    try:
                        # MACCSフィンガープリントを計算
                        fragments = self._generate_fragment_features(mol)
                        fragment_patterns[mol_id] = fragments
                    except Exception as e:
                        # フラグメント計算に失敗した場合は0ベクトルを使用
                        fragment_patterns[mol_id] = np.zeros(NUM_FRAGS)
                        
                except Exception as e:
                    continue
                    
            except Exception as e:
                continue
                
        self.valid_mol_ids = valid_ids
        self.fragment_patterns = fragment_patterns
        
    def _generate_fragment_features(self, mol):
        """分子のフラグメント特徴量を生成"""
        # MACCSフィンガープリントを計算
        maccs = MACCSkeys.GenMACCSKeys(mol)
        maccs_bits = np.zeros(NUM_FRAGS)
        
        # ビットを取得
        for i in range(NUM_FRAGS):
            if maccs.GetBit(i):
                maccs_bits[i] = 1.0
                
        return maccs_bits
        
    def __len__(self):
        return len(self.valid_mol_ids)
    
    def __getitem__(self, idx):
        mol_id = self.valid_mol_ids[idx]
        mol_file = os.path.join(self.mol_files_path, f"ID{mol_id}.MOL")
        
        # MOLファイルからグラフ表現を生成
        graph_data = self._mol_to_graph(mol_file)
        
        # MSPデータからマススペクトルを取得
        mass_spectrum = self.msp_data.get(mol_id, np.zeros(MAX_MZ))
        mass_spectrum = self._preprocess_spectrum(mass_spectrum)
        
        # フラグメントパターンを取得
        fragment_pattern = self.fragment_patterns.get(mol_id, np.zeros(NUM_FRAGS))
        
        return graph_data, torch.FloatTensor(mass_spectrum), torch.FloatTensor(fragment_pattern)
    
    def _preprocess_spectrum(self, spectrum):
        """スペクトルの前処理を強化"""
        # ピークの強調 (非ゼロ値のみを考慮)
        non_zero_indices = np.nonzero(spectrum)[0]
        if len(non_zero_indices) > 0:
            # 上位30%のピークを強調
            threshold = np.percentile(spectrum[non_zero_indices], 70)
            spectrum_enhanced = spectrum.copy()
            spectrum_enhanced[spectrum > threshold] *= 1.2
            
            # 特徴的なm/z値のピークを強調
            for mz in IMPORTANT_MZ:
                if mz < len(spectrum_enhanced) and spectrum_enhanced[mz] > 0:
                    spectrum_enhanced[mz] *= 1.5
            
            # 正規化
            if np.max(spectrum_enhanced) > 0:
                spectrum_enhanced = spectrum_enhanced / np.max(spectrum_enhanced) * 100
            
            # スムージング
            smoothed = np.zeros_like(spectrum_enhanced)
            for i in range(len(spectrum_enhanced)):
                window_start = max(0, i - 1)
                window_end = min(len(spectrum_enhanced), i + 2)
                smoothed[i] = np.mean(spectrum_enhanced[window_start:window_end])
            
            # ノイズ除去（小さなピークを除去）
            noise_threshold = 1.0
            smoothed[smoothed < noise_threshold] = 0.0
            
            return smoothed
            
        return spectrum
        
    def _mol_to_graph(self, mol_file):
        """分子をグラフに変換（拡張特徴量あり、エラー処理強化）"""
        # RDKitでMOLファイルを読み込む (サニタイズを無効にして読み込む)
        mol = Chem.MolFromMolFile(mol_file, sanitize=False)
        if mol is None:
            raise ValueError(f"Could not read molecule from {mol_file}")
        
        # 拡張機能: 特徴量の追加
        try:
            # プロパティキャッシュを更新して暗黙的な原子価を計算
            for atom in mol.GetAtoms():
                atom.UpdatePropertyCache(strict=False)
            
            # 部分的なサニタイズ（エラーが発生しやすい操作を除外）
            Chem.SanitizeMol(mol, 
                           sanitizeOps=Chem.SanitizeFlags.SANITIZE_FINDRADICALS|
                                      Chem.SanitizeFlags.SANITIZE_KEKULIZE|
                                      Chem.SanitizeFlags.SANITIZE_SETAROMATICITY|
                                      Chem.SanitizeFlags.SANITIZE_SETCONJUGATION|
                                      Chem.SanitizeFlags.SANITIZE_SETHYBRIDIZATION|
                                      Chem.SanitizeFlags.SANITIZE_SYMMRINGS,
                           catchErrors=True)
            
            # 明示的な水素を追加（安全モード）
            try:
                mol = Chem.AddHs(mol)
            except:
                pass
        except Exception as e:
            # それでも処理を続行
            pass
        
        # 原子情報を取得（拡張特徴量）
        num_atoms = mol.GetNumAtoms()
        x = []
        
        # 特殊な環境の原子を特定（マルチタスク学習用）
        # 修正: GetSSSR()ではなくGetRingInfo().AtomRings()を使用
        ring_info = mol.GetRingInfo().AtomRings()
        aromatic_rings = 0
        for ring in ring_info:
            if all(mol.GetAtomWithIdx(idx).GetIsAromatic() for idx in ring):
                aromatic_rings += 1
                
        for atom in mol.GetAtoms():
            atom_symbol = atom.GetSymbol()
            atom_feature_idx = ATOM_FEATURES.get(atom_symbol, ATOM_FEATURES['OTHER'])
            
            # 基本的な原子タイプの特徴
            atom_feature = [0] * len(ATOM_FEATURES)
            atom_feature[atom_feature_idx] = 1
            
            # 修正: 安全なメソッド呼び出し
            try:
                degree = atom.GetDegree() / 8.0
            except:
                degree = 0.0
                
            try:
                formal_charge = atom.GetFormalCharge() / 8.0
            except:
                formal_charge = 0.0
                
            try:
                radical_electrons = atom.GetNumRadicalElectrons() / 4.0
            except:
                radical_electrons = 0.0
                
            try:
                is_aromatic = atom.GetIsAromatic() * 1.0
            except:
                is_aromatic = 0.0
                
            try:
                atom_mass = atom.GetMass() / 200.0
            except:
                atom_mass = 0.0
                
            try:
                is_in_ring = atom.IsInRing() * 1.0
            except:
                is_in_ring = 0.0
                
            try:
                hybridization = int(atom.GetHybridization()) / 8.0
            except:
                hybridization = 0.0
                
            try:
                explicit_valence = atom.GetExplicitValence() / 8.0
            except:
                explicit_valence = 0.0
                
            try:
                implicit_valence = atom.GetImplicitValence() / 8.0
            except:
                implicit_valence = 0.0
                
            # 追加の環境特徴量
            try:
                is_in_aromatic_ring = (atom.GetIsAromatic() and atom.IsInRing()) * 1.0
            except:
                is_in_aromatic_ring = 0.0
                
            try:
                ring_size = 0
                for ring in ring_info:
                    if atom.GetIdx() in ring:
                        ring_size = max(ring_size, len(ring))
                ring_size = ring_size / 8.0
            except:
                ring_size = 0.0
                
            try:
                num_h = atom.GetTotalNumHs() / 8.0
            except:
                num_h = 0.0
                
            try:
                electronegativity = 0.0
                if atom_symbol in ['O', 'N', 'F', 'Cl', 'Br', 'I']:
                    electronegativity = 1.0
            except:
                electronegativity = 0.0
            
            # ファンシー特徴量（質量分析に関連する特徴）
            try:
                # 典型的なフラグメンテーションサイト
                is_carbonyl_carbon = 0.0
                is_carbonyl_oxygen = 0.0
                neighbors = [n.GetSymbol() for n in atom.GetNeighbors()]
                
                if atom_symbol == 'C' and 'O' in neighbors:
                    for n in atom.GetNeighbors():
                        if n.GetSymbol() == 'O' and n.GetTotalNumHs() == 0:
                            is_carbonyl_carbon = 1.0
                            
                if atom_symbol == 'O' and 'C' in neighbors and atom.GetTotalNumHs() == 0:
                    is_carbonyl_oxygen = 1.0
            except:
                is_carbonyl_carbon = 0.0
                is_carbonyl_oxygen = 0.0
            
            # すべての特徴を結合（基本+拡張特徴量）
            additional_features = [
                degree,                # 結合次数（正規化）
                formal_charge,         # 形式電荷（正規化）
                radical_electrons,     # ラジカル電子数
                is_aromatic,           # 芳香族性
                atom_mass,             # 原子量（正規化）
                is_in_ring,            # 環の一部かどうか
                hybridization,         # 混成軌道
                explicit_valence,      # 原子価
                implicit_valence,      # 暗黙の原子価
                is_in_aromatic_ring,   # 芳香環の一部か
                ring_size,             # 含まれる環のサイズ
                num_h,                 # 水素原子数
                electronegativity,     # 電気陰性度（簡易）
                is_carbonyl_carbon,    # カルボニル炭素か
                is_carbonyl_oxygen,    # カルボニル酸素か
            ]
            
            # すべての特徴を結合
            atom_feature.extend(additional_features)
            x.append(atom_feature)
        
        # 結合情報を取得（拡張特徴量）
        edge_indices = []
        edge_attrs = []
        for bond in mol.GetBonds():
            try:
                i = bond.GetBeginAtomIdx()
                j = bond.GetEndAtomIdx()
                
                # 結合タイプ（デフォルトはSINGLE）
                try:
                    bond_type = BOND_FEATURES.get(bond.GetBondType(), BOND_FEATURES[Chem.rdchem.BondType.SINGLE])
                except:
                    bond_type = BOND_FEATURES[Chem.rdchem.BondType.SINGLE]
                
                # 双方向のエッジを追加
                edge_indices.append([i, j])
                edge_indices.append([j, i])
                
                # 拡張ボンド特徴量
                bond_feature = [0] * len(BOND_FEATURES)
                bond_feature[bond_type] = 1
                
                # 安全な追加ボンド特徴量の取得
                try:
                    is_in_ring = bond.IsInRing() * 1.0
                except:
                    is_in_ring = 0.0
                    
                try:
                    is_conjugated = bond.GetIsConjugated() * 1.0
                except:
                    is_conjugated = 0.0
                    
                try:
                    is_aromatic = bond.GetIsAromatic() * 1.0
                except:
                    is_aromatic = 0.0
                    
                try:
                    stereo = int(bond.GetStereo()) / 8.0
                except:
                    stereo = 0.0
                    
                # フラグメントに関連する特徴
                try:
                    is_rotatable = (not bond.IsInRing()) * 1.0
                except:
                    is_rotatable = 0.0
                    
                try:
                    bond_length = 0.5  # デフォルト値
                    try:
                        # 3D座標がある場合、ボンド長を計算
                        conf = mol.GetConformer()
                        pos1 = conf.GetAtomPosition(i)
                        pos2 = conf.GetAtomPosition(j)
                        bond_length = ((pos1.x - pos2.x)**2 + 
                                      (pos1.y - pos2.y)**2 + 
                                      (pos1.z - pos2.z)**2) ** 0.5 / 5.0  # 正規化
                    except:
                        pass
                except:
                    bond_length = 0.5
                
                # 追加ボンド特徴量
                additional_bond_features = [
                    is_in_ring,          # 環の一部かどうか
                    is_conjugated,       # 共役かどうか
                    is_aromatic,         # 芳香族かどうか
                    stereo,              # 立体化学
                    is_rotatable,        # 回転可能な結合か
                    bond_length,         # 結合長（正規化）
                ]
                
                bond_feature.extend(additional_bond_features)
                edge_attrs.append(bond_feature)
                edge_attrs.append(bond_feature)  # 双方向なので同じ属性
            except Exception as e:
                continue
        
        # 分子全体の特徴量を計算（安全に）
        mol_features = [0.0] * 16  # デフォルト値で初期化
        
        try:
            mol_features[0] = Descriptors.MolWt(mol) / 1000.0  # 分子量
        except:
            pass
            
        try:
            mol_features[1] = Descriptors.MolLogP(mol) / 10.0  # LogP
        except:
            pass
            
        try:
            mol_features[2] = Descriptors.NumHAcceptors(mol) / 20.0  # 水素結合アクセプター数
        except:
            pass
            
        try:
            mol_features[3] = Descriptors.NumHDonors(mol) / 10.0  # 水素結合ドナー数
        except:
            pass
            
        try:
            mol_features[4] = Descriptors.TPSA(mol) / 200.0  # トポロジカル極性表面積
        except:
            pass
            
        try:
            mol_features[5] = mol.GetNumAtoms() / 100.0  # 原子数
        except:
            pass
            
        try:
            mol_features[6] = Descriptors.NumRotatableBonds(mol) / 20.0  # 回転可能な結合の数
        except:
            pass
            
        try:
            mol_features[7] = Descriptors.NumAromaticRings(mol) / 5.0  # 芳香環の数
        except:
            pass
            
        try:
            mol_features[8] = Descriptors.FractionCSP3(mol)  # sp3炭素の割合
        except:
            pass
            
        try:
            mol_features[9] = Descriptors.NumAliphaticRings(mol) / 5.0  # 脂肪環の数
        except:
            pass
            
        try:
            mol_features[10] = Descriptors.NumAliphaticHeterocycles(mol) / 5.0  # 脂肪族ヘテロ環の数
        except:
            pass
            
        try:
            mol_features[11] = Descriptors.NumAromaticHeterocycles(mol) / 5.0  # 芳香族ヘテロ環の数
        except:
            pass
            
        try:
            mol_features[12] = Descriptors.NumSaturatedRings(mol) / 5.0  # 飽和環の数
        except:
            pass
            
        try:
            mol_features[13] = Descriptors.NumHeteroatoms(mol) / 20.0  # ヘテロ原子の数
        except:
            pass
            
        try:
            mol_features[14] = Descriptors.RingCount(mol) / 10.0  # 環の総数
        except:
            pass
            
        try:
            # 質量分析に関連する特徴量
            carbonyl_count = 0
            for atom in mol.GetAtoms():
                if atom.GetSymbol() == 'C':
                    for neighbor in atom.GetNeighbors():
                        if neighbor.GetSymbol() == 'O' and neighbor.GetTotalNumHs() == 0:
                            carbonyl_count += 1
                            break
            mol_features[15] = carbonyl_count / 10.0  # カルボニル基の数
        except:
            pass
        
        # エッジが存在するか確認
        if not edge_indices:
            # 単一原子分子の場合や結合情報が取得できない場合、セルフループを追加
            for i in range(num_atoms):
                edge_indices.append([i, i])
                
                bond_feature = [0] * len(BOND_FEATURES)
                bond_feature[BOND_FEATURES[Chem.rdchem.BondType.SINGLE]] = 1
                
                # ダミーの追加特徴量
                additional_bond_features = [0.0, 0.0, 0.0, 0.0, 0.0, 0.5]
                bond_feature.extend(additional_bond_features)
                edge_attrs.append(bond_feature)
        
        # PyTorch Geometricのデータ形式に変換
        x = torch.FloatTensor(x)
        edge_index = torch.LongTensor(edge_indices).t().contiguous()
        edge_attr = torch.FloatTensor(edge_attrs)
        global_attr = torch.FloatTensor(mol_features)
        
        # データ拡張（トレーニング時のみ）
        if self.augment and np.random.random() < 0.3:
            # ノイズ追加
            x = x + torch.randn_like(x) * 0.01
            edge_attr = edge_attr + torch.randn_like(edge_attr) * 0.01
        
        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, global_attr=global_attr)
```

## 6. マススペクトルデータ解析関数

```python
def parse_msp_file(msp_file_path):
    """MSPファイルを解析し、ID->マススペクトルのマッピングを返す"""
    msp_data = {}
    current_id = None
    current_peaks = []
    
    with open(msp_file_path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            line = line.strip()
            
            # IDを検出
            if line.startswith("ID:"):
                current_id = line.split(":")[1].strip()
                current_id = int(current_id)
            
            # ピーク数を検出（これはピークデータの直前にある）
            elif line.startswith("Num peaks:"):
                current_peaks = []
            
            # 空行は化合物の区切り
            elif line == "" and current_id is not None and current_peaks:
                # マススペクトルをベクトルに変換
                ms_vector = np.zeros(MAX_MZ)
                for mz, intensity in current_peaks:
                    if 0 <= mz < MAX_MZ:
                        ms_vector[mz] = intensity
                
                # 強度を正規化
                if np.sum(ms_vector) > 0:
                    ms_vector = ms_vector / np.max(ms_vector) * 100
                    
                    # スペクトルをスムージング
                    smoothed_vector = np.zeros_like(ms_vector)
                    for i in range(len(ms_vector)):
                        start = max(0, i-1)
                        end = min(len(ms_vector), i+2)
                        smoothed_vector[i] = np.mean(ms_vector[start:end])
                    
                    # 小さなピークをフィルタリング (ノイズ除去)
                    threshold = np.percentile(smoothed_vector[smoothed_vector > 0], 10)
                    smoothed_vector[smoothed_vector < threshold] = 0
                    
                    # 重要なm/z値のピークを強調
                    for mz in IMPORTANT_MZ:
                        if mz < len(smoothed_vector) and smoothed_vector[mz] > 0:
                            smoothed_vector[mz] *= 1.5
                    
                    msp_data[current_id] = smoothed_vector
                else:
                    msp_data[current_id] = ms_vector
                
                current_id = None
                current_peaks = []
            
            # ピークデータを処理
            elif current_id is not None and " " in line and not any(line.startswith(prefix) for prefix in ["Name:", "Formula:", "MW:", "ExactMass:", "CASNO:", "Comment:"]):
                try:
                    parts = line.split()
                    if len(parts) == 2:
                        mz = int(parts[0])
                        intensity = float(parts[1])
                        current_peaks.append((mz, intensity))
                except ValueError:
                    pass  # 数値に変換できない行はスキップ
    
    return msp_data
```

## 7. モデル訓練と評価関数

```python
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device):
    """モデルの学習を行う（改良版）"""
    train_losses = []
    val_losses = []
    val_cosine_similarities = []
    best_cosine = 0.0
    early_stopping_counter = 0
    early_stopping_patience = 15
    
    for epoch in range(num_epochs):
        # 訓練モード
        model.train()
        epoch_loss = 0
        batch_count = 0
        
        for graph_data, mass_spectrum, fragment_pattern in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} (Training)"):
            try:
                # データをGPUに転送
                graph_data = graph_data.to(device)
                mass_spectrum = mass_spectrum.to(device)
                fragment_pattern = fragment_pattern.to(device)
                
                # バッチサイズの確認
                batch_size = graph_data.batch[-1].item() + 1 if hasattr(graph_data, 'batch') and graph_data.batch.numel() > 0 else 1
                
                # 勾配をゼロに初期化
                optimizer.zero_grad()
                
                # 順伝播
                output, fragment_pred = model(graph_data)
                
                # バッチサイズの不一致を処理
                if output.size(0) != mass_spectrum.size(0):
                    min_batch_size = min(output.size(0), mass_spectrum.size(0))
                    output = output[:min_batch_size]
                    mass_spectrum = mass_spectrum[:min_batch_size]
                    fragment_pred = fragment_pred[:min_batch_size]
                    fragment_pattern = fragment_pattern[:min_batch_size]
                
                # 損失計算
                loss = criterion(output, mass_spectrum, fragment_pred, fragment_pattern)
                
                # 逆伝播
                loss.backward()
                
                # 勾配クリッピング（勾配爆発を防止）
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                optimizer.step()
                
                epoch_loss += loss.item()
                batch_count += 1
                
            except RuntimeError as e:
                print(f"エラーが発生しました: {str(e)}")
                print(f"バッチサイズ: {batch_size}")
                continue
        
        # バッチ処理が成功したか確認
        if batch_count > 0:
            train_losses.append(epoch_loss / batch_count)
        else:
            print("警告：このエポックで成功したバッチ処理がありません。")
            train_losses.append(float('inf'))
        
        # 評価モード
        model.eval()
        val_loss = 0
        val_batch_count = 0
        y_true = []
        y_pred = []
        
        with torch.no_grad():
            for graph_data, mass_spectrum, fragment_pattern in tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} (Validation)"):
                try:
                    graph_data = graph_data.to(device)
                    mass_spectrum = mass_spectrum.to(device)
                    fragment_pattern = fragment_pattern.to(device)
                    
                    output, fragment_pred = model(graph_data)
                    
                    # バッチサイズの不一致を処理
                    if output.size(0) != mass_spectrum.size(0):
                        min_batch_size = min(output.size(0), mass_spectrum.size(0))
                        output = output[:min_batch_size]
                        mass_spectrum = mass_spectrum[:min_batch_size]
                        fragment_pred = fragment_pred[:min_batch_size]
                        fragment_pattern = fragment_pattern[:min_batch_size]
                    
                    loss = criterion(output, mass_spectrum, fragment_pred, fragment_pattern)
                    val_loss += loss.item()
                    val_batch_count += 1
                    
                    y_true.append(mass_spectrum.cpu().numpy())
                    y_pred.append(output.cpu().numpy())
                    
                except RuntimeError as e:
                    print(f"評価中にエラーが発生しました: {str(e)}")
                    continue
        
        # バッチ処理が成功したか確認
        if val_batch_count > 0:
            val_losses.append(val_loss / val_batch_count)
        else:
            print("警告：評価中に成功したバッチ処理がありません。")
            val_losses.append(float('inf'))
        
        # コサイン類似度を計算
        if y_true and y_pred:  # リストが空でないことを確認
            try:
                y_true_concat = np.concatenate(y_true)
                y_pred_concat = np.concatenate(y_pred)
                cosine_sim = cosine_similarity_score(y_true_concat, y_pred_concat)
                val_cosine_similarities.append(cosine_sim)
            except Exception as e:
                print(f"コサイン類似度計算中にエラーが発生しました: {str(e)}")
                val_cosine_similarities.append(0.0)
                cosine_sim = 0.0
        else:
            val_cosine_similarities.append(0.0)
            cosine_sim = 0.0
        
        # 学習率スケジューラーの更新
        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):
            scheduler.step(val_losses[-1])
        else:
            scheduler.step()
        
        print(f"Epoch {epoch+1}/{num_epochs}, "
              f"Train Loss: {train_losses[-1]:.4f}, "
              f"Val Loss: {val_losses[-1]:.4f}, "
              f"Val Cosine Similarity: {cosine_sim:.4f}, "
              f"LR: {optimizer.param_groups[0]['lr']:.6f}")
        
        # 最良モデルの保存
        if cosine_sim > best_cosine:
            best_cosine = cosine_sim
            early_stopping_counter = 0
            torch.save(model.state_dict(), 'models/best_specialized_model.pth')
            print(f"新しい最良モデル保存: {cosine_sim:.4f}")
        else:
            early_stopping_counter += 1
            
        # 早期停止
        if early_stopping_counter >= early_stopping_patience:
            print(f"Early stopping triggered after {epoch+1} epochs")
            break
    
    return train_losses, val_losses, val_cosine_similarities
```

## 8. 分子クラスタリング・類似分子選択関数

```python
def find_similar_molecules(target_smiles, mol_files_path, msp_data, n_similar=1000):
    """
    ターゲット分子に構造的に類似した分子を見つける
    
    Args:
        target_smiles: ターゲット分子のSMILES文字列
        mol_files_path: MOLファイルのディレクトリパス
        msp_data: IDからマススペクトルへのマッピング
        n_similar: 返す類似分子の数
    
    Returns:
        list: 類似分子のID一覧
        list: 類似度スコア一覧
    """
    print(f"検索対象分子: {target_smiles}")
    
    # ターゲットSMILESから分子を生成しフィンガープリントを得る
    target_mol = Chem.MolFromSmiles(target_smiles)
    if target_mol is None:
        raise ValueError(f"SMILESから分子を生成できませんでした: {target_smiles}")
    
    # ターゲット分子のMorganフィンガープリント(ECFP)を生成
    target_fp = AllChem.GetMorganFingerprintAsBitVect(target_mol, 3, nBits=2048)
    
    # データセット内のすべての分子を処理
    all_mol_ids = []
    all_fps = []
    
    print("分子処理とフィンガープリント生成中...")
    for filename in tqdm(os.listdir(mol_files_path)):
        if filename.startswith("ID") and filename.endswith(".MOL"):
            mol_id = int(filename[2:-4])
            
            # MSPデータがある分子のみ処理
            if mol_id not in msp_data:
                continue
                
            mol_file = os.path.join(mol_files_path, filename)
            
            try:
                # 分子を読み込みとサニタイズ
                mol = Chem.MolFromMolFile(mol_file, sanitize=False)
                if mol is None:
                    continue
                    
                # エラー処理付きサニタイズ
                for atom in mol.GetAtoms():
                    atom.UpdatePropertyCache(strict=False)
                
                try:
                    Chem.SanitizeMol(mol, 
                                    sanitizeOps=Chem.SanitizeFlags.SANITIZE_FINDRADICALS|
                                               Chem.SanitizeFlags.SANITIZE_KEKULIZE|
                                               Chem.SanitizeFlags.SANITIZE_SETAROMATICITY|
                                               Chem.SanitizeFlags.SANITIZE_SETCONJUGATION|
                                               Chem.SanitizeFlags.SANITIZE_SETHYBRIDIZATION|
                                               Chem.SanitizeFlags.SANITIZE_SYMMRINGS,
                                    catchErrors=True)
                except:
                    continue
                
                # フィンガープリント生成
                fp = AllChem.GetMorganFingerprintAsBitVect(mol, 3, nBits=2048)
                
                all_mol_ids.append(mol_id)
                all_fps.append(fp)
                
            except Exception as e:
                continue
    
    # 類似度計算
    print(f"{len(all_fps)}個の分子の類似度を計算しています...")
    similarities = []
    
    for fp in all_fps:
        similarity = DataStructs.TanimotoSimilarity(target_fp, fp)
        similarities.append(similarity)
    
    # 類似度でソート（高い順）
    sorted_indices = np.argsort(similarities)[::-1]
    
    # 上位n_similar個の分子を取得
    top_mol_ids = [all_mol_ids[idx] for idx in sorted_indices[:n_similar]]
    top_similarities = [similarities[idx] for idx in sorted_indices[:n_similar]]
    
    print(f"{len(top_mol_ids)}個の類似分子を検出")
    print(f"類似度範囲: {top_similarities[0]:.4f} - {top_similarities[-1]:.4f}")
    
    return top_mol_ids, top_similarities

def visualize_similarity_distribution(similarities, filename="plots/similarity_distribution.png"):
    """類似度分布の可視化"""
    plt.figure(figsize=(10, 6))
    plt.hist(similarities, bins=50, alpha=0.75)
    plt.xlabel('Tanimoto類似度')
    plt.ylabel('分子数')
    plt.title('分子類似度の分布')
    plt.axvline(x=np.mean(similarities), color='r', linestyle='--', label=f'平均: {np.mean(similarities):.4f}')
    plt.axvline(x=np.median(similarities), color='g', linestyle='--', label=f'中央値: {np.median(similarities):.4f}')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.savefig(filename)
    plt.close()
    print(f"類似度分布グラフを{filename}に保存しました")

def visualize_representative_molecules(similar_mol_ids, similarities, mol_files_path, n=10, filename="plots/representative_molecules.png"):
    """代表的な類似分子を可視化"""
    # 類似度の高い分子IDを取得
    top_indices = np.argsort(similarities)[-n:][::-1]
    top_mol_ids = [similar_mol_ids[i] for i in top_indices]
    top_similarities = [similarities[i] for i in top_indices]
    
    # 分子を読み込み
    mols = []
    legends = []
    
    for mol_id, sim in zip(top_mol_ids, top_similarities):
        mol_file = os.path.join(mol_files_path, f"ID{mol_id}.MOL")
        try:
            mol = Chem.MolFromMolFile(mol_file, sanitize=False)
            if mol is None:
                continue
                
            # 分子のサニタイズ
            for atom in mol.GetAtoms():
                atom.UpdatePropertyCache(strict=False)
            
            Chem.SanitizeMol(mol, 
                           sanitizeOps=Chem.SanitizeFlags.SANITIZE_ALL,
                           catchErrors=True)
            
            mols.append(mol)
            legends.append(f"ID{mol_id}\nSim: {sim:.4f}")
        except Exception as e:
            continue
    
    # 分子を描画
    if mols:
        img = Draw.MolsToGridImage(mols, molsPerRow=5, subImgSize=(300, 300), legends=legends)
        img.save(filename)
        print(f"代表的分子を{filename}に保存しました")
    else:
        print("代表的分子の可視化に失敗しました")
```

## 9. モデル評価と可視化関数

```python
def extract_embeddings(model, dataloader, device):
    """モデルからの埋め込み特徴を抽出"""
    model.eval()
    embeddings = []
    mol_ids = []
    
    with torch.no_grad():
        for batch_idx, (graph_data, mass_spectrum, _) in enumerate(tqdm(dataloader, desc="Extracting embeddings")):
            # データをデバイスに転送
            graph_data = graph_data.to(device)
            
            # モデルから埋め込みを抽出
            x, edge_index, edge_attr, batch = graph_data.x, graph_data.edge_index, graph_data.edge_attr, graph_data.batch
            global_attr = graph_data.global_attr
            
            # GNN層を通した処理
            x1 = model.act(model.conv1(x, edge_index, edge_attr))
            x1 = model.dropout(x1)
            
            x2 = model.act(model.conv2(x1, edge_index, edge_attr))
            x2 = model.dropout(x2)
            
            x1_transformed = model.skip_connection1(x1)
            x2 = x2 + x1_transformed
            x2 = model.ln1(x2)
            
            x3 = model.act(model.conv3(x2, edge_index, edge_attr))
            x3 = model.dropout(x3)
            
            x4 = model.act(model.conv4(x3, edge_index, edge_attr))
            x4 = model.dropout(x4)
            
            x2_transformed = model.skip_connection2(x2)
            x4 = x4 + x2_transformed
            
            x5 = model.act(model.conv5(x4, edge_index, edge_attr))
            
            # グローバルプーリング
            x_graph = global_mean_pool(x5, batch)
            
            # グローバル特徴量の処理
            global_features = model.global_proj(global_attr)
            
            # 特徴量の結合が埋め込み表現
            embedding = torch.cat([x_graph, global_features], dim=1)
            
            # 埋め込みを保存
            embeddings.append(embedding.cpu().numpy())
            
            # このバッチの分子IDを取得
            batch_size = graph_data.batch[-1].item() + 1
            for i in range(batch_size):
                idx = batch_idx * dataloader.batch_size + i
                if idx < len(dataloader.dataset):
                    # データセットを通して分子IDにアクセス
                    if hasattr(dataloader.dataset, 'valid_mol_ids'):
                        # MoleculeGraphDatasetからの直接アクセス
                        mol_id = dataloader.dataset.valid_mol_ids[idx]
                    elif hasattr(dataloader.dataset, 'dataset') and hasattr(dataloader.dataset.dataset, 'valid_mol_ids'):
                        # random_splitラッパーを通してのアクセス
                        dataset_idx = dataloader.dataset.indices[idx]
                        mol_id = dataloader.dataset.dataset.valid_mol_ids[dataset_idx]
                    else:
                        mol_id = idx  # フォールバック
                    mol_ids.append(mol_id)
    
    # すべての埋め込みを結合
    embeddings = np.vstack(embeddings)
    
    return embeddings, mol_ids

def visualize_molecule_clusters(embeddings, mol_ids, similarities=None, n_components=2, method='tsne', filename='plots/molecule_clusters.png'):
    """分子クラスターの可視化"""
    # 次元削減を適用
    if method.lower() == 'tsne':
        reducer = TSNE(n_components=n_components, random_state=42)
    else:
        reducer = PCA(n_components=n_components)
    
    reduced_embeddings = reducer.fit_transform(embeddings)
    
    # 可視化
    plt.figure(figsize=(12, 10))
    
    if similarities is not None:
        # 類似度によるポイントの色付け
        scatter = plt.scatter(
            reduced_embeddings[:, 0], 
            reduced_embeddings[:, 1],
            c=similarities,
            cmap='viridis',
            alpha=0.7,
            s=50
        )
        plt.colorbar(scatter, label='ターゲット分子への類似度')
    else:
        plt.scatter(
            reduced_embeddings[:, 0], 
            reduced_embeddings[:, 1],
            alpha=0.7,
            s=50
        )
    
    plt.title(f'分子クラスター ({method.upper()})')
    plt.xlabel('成分 1')
    plt.ylabel('成分 2')
    plt.tight_layout()
    plt.savefig(filename, dpi=300)
    plt.close()
    
    return reduced_embeddings

def evaluate_model(model, test_dataset, device):
    """モデルの評価"""
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)
    
    model.eval()
    test_loss = 0
    batch_count = 0
    y_true = []
    y_pred = []
    
    with torch.no_grad():
        for graph_data, mass_spectrum, fragment_pattern in tqdm(test_loader, desc="Testing"):
            try:
                graph_data = graph_data.to(device)
                mass_spectrum = mass_spectrum.to(device)
                fragment_pattern = fragment_pattern.to(device)
                
                output, fragment_pred = model(graph_data)
                
                # バッチサイズの不一致を処理
                if output.size(0) != mass_spectrum.size(0):
                    min_batch_size = min(output.size(0), mass_spectrum.size(0))
                    output = output[:min_batch_size]
                    mass_spectrum = mass_spectrum[:min_batch_size]
                    fragment_pred = fragment_pred[:min_batch_size]
                    fragment_pattern = fragment_pattern[:min_batch_size]
                
                loss = combined_loss(output, mass_spectrum, fragment_pred, fragment_pattern)
                test_loss += loss.item()
                batch_count += 1
                
                y_true.append(mass_spectrum.cpu().numpy())
                y_pred.append(output.cpu().numpy())
                
            except RuntimeError as e:
                print(f"テスト中にエラーが発生しました: {str(e)}")
                continue
    
    # バッチ処理が成功したか確認
    if batch_count > 0:
        avg_test_loss = test_loss / batch_count
    else:
        print("警告：テスト中に成功したバッチ処理がありません。")
        avg_test_loss = float('inf')
    
    # コサイン類似度を計算
    if y_true and y_pred:  # リストが空でないことを確認
        try:
            y_true_concat = np.concatenate(y_true)
            y_pred_concat = np.concatenate(y_pred)
            test_cosine_sim = cosine_similarity_score(y_true_concat, y_pred_concat)
        except Exception as e:
            print(f"コサイン類似度計算中にエラーが発生しました: {str(e)}")
            test_cosine_sim = 0.0
    else:
        test_cosine_sim = 0.0
    
    print(f"テスト損失: {avg_test_loss:.4f}")
    print(f"テストコサイン類似度: {test_cosine_sim:.4f}")
    
    return avg_test_loss, test_cosine_sim, y_true_concat, y_pred_concat

def visualize_spectrum_predictions(y_true, y_pred, n_samples=5, filename="plots/spectrum_predictions.png"):
    """マススペクトル予測の可視化"""
    # 最もコサイン類似度の高いサンプルを見つける
    sample_similarities = []
    
    for i in range(len(y_true)):
        true_spec = y_true[i]
        pred_spec = y_pred[i]
        
        # コサイン類似度を計算
        similarity = cosine_similarity(
            true_spec.reshape(1, -1), 
            pred_spec.reshape(1, -1)
        )[0][0]
        
        sample_similarities.append((i, similarity))
    
    # コサイン類似度で降順ソート
    sample_similarities.sort(key=lambda x: x[1], reverse=True)
    
    # 上位n_samplesサンプルの可視化
    plt.figure(figsize=(15, 4 * n_samples))
    
    for i in range(min(n_samples, len(sample_similarities))):
        idx, similarity = sample_similarities[i]
        true_spec = y_true[idx]
        pred_spec = y_pred[idx]
        
        plt.subplot(n_samples, 2, 2*i + 1)
        plt.stem(np.arange(len(true_spec)), true_spec, markerfmt=" ")
        plt.xlabel('m/z')
        plt.ylabel('強度')
        plt.title(f'実測スペクトル - サンプル {i+1}')
        
        plt.subplot(n_samples, 2, 2*i + 2)
        plt.stem(np.arange(len(pred_spec)), pred_spec, markerfmt=" ", linefmt='r-')
        plt.xlabel('m/z')
        plt.ylabel('強度')
        plt.title(f'予測スペクトル - コサイン類似度: {similarity:.4f}')
    
    plt.tight_layout()
    plt.savefig(filename)
    plt.close()

def compare_general_vs_specialized(similar_mol_ids, mol_files_path, msp_data):
    """汎用モデルと特化型モデルの比較"""
    # データセットの作成
    dataset = MoleculeGraphDataset(similar_mol_ids, MOL_FILES_PATH, msp_data, augment=False)
    
    # データを分割
    test_size = int(0.2 * len(dataset))
    train_size = len(dataset) - test_size
    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])
    
    # デバイスの設定
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # サンプルデータから特徴量の次元を取得
    sample_data = dataset[0][0]
    node_features = sample_data.x.size(1)
    edge_features = sample_data.edge_attr.size(1)
    
    # 汎用モデルをロード
    general_model = HybridGNNModel(node_features, edge_features, HIDDEN_CHANNELS, MAX_MZ).to(device)
    general_model.load_state_dict(torch.load('models/best_gcn_ms_model.pth', map_location=device))
    
    # 特化型モデルをロード
    specialized_model = HybridGNNModel(node_features, edge_features, HIDDEN_CHANNELS, MAX_MZ).to(device)
    specialized_model.load_state_dict(torch.load('models/best_specialized_model.pth', map_location=device))
    
    # テストデータローダー
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)
    
    # 比較結果を保存するリスト
    general_scores = []
    specialized_scores = []
    
    # 評価
    general_model.eval()
    specialized_model.eval()
    
    with torch.no_grad():
        for graph_data, mass_spectrum, _ in tqdm(test_loader, desc="Comparing models"):
            graph_data = graph_data.to(device)
            mass_spectrum = mass_spectrum.to(device)
            
            # 汎用モデルで予測
            output_general, _ = general_model(graph_data)
            
            # 特化型モデルで予測
            output_specialized, _ = specialized_model(graph_data)
            
            # 各分子のコサイン類似度を計算
            for i in range(output_general.size(0)):
                pred_general = output_general[i].unsqueeze(0)
                pred_specialized = output_specialized[i].unsqueeze(0)
                true = mass_spectrum[i].unsqueeze(0)
                
                # 正規化
                pred_general_norm = F.normalize(pred_general, p=2, dim=1)
                pred_specialized_norm = F.normalize(pred_specialized, p=2, dim=1)
                true_norm = F.normalize(true, p=2, dim=1)
                
                # コサイン類似度の計算
                cosine_general = torch.sum(pred_general_norm * true_norm, dim=1).item()
                cosine_specialized = torch.sum(pred_specialized_norm * true_norm, dim=1).item()
                
                general_scores.append(cosine_general)
                specialized_scores.append(cosine_specialized)
    
    # 比較の可視化
    plt.figure(figsize=(10, 6))
    plt.scatter(general_scores, specialized_scores, alpha=0.5)
    plt.plot([0, 1], [0, 1], 'r--')  # 対角線
    plt.xlabel('汎用モデルのコサイン類似度')
    plt.ylabel('特化型モデルのコサイン類似度')
    plt.title('汎用モデルと特化型モデルの性能比較')
    plt.grid(True, alpha=0.3)
    plt.savefig('plots/model_comparison.png')
    plt.close()
    
    # 改善度の計算
    improvements = np.array(specialized_scores) - np.array(general_scores)
    mean_improvement = np.mean(improvements)
    
    # 改善度のヒストグラム
    plt.figure(figsize=(10, 6))
    plt.hist(improvements, bins=50, alpha=0.75)
    plt.axvline(x=0, color='r', linestyle='--')
    plt.xlabel('コサイン類似度の改善度')
    plt.ylabel('分子数')
    plt.title('特化型モデルによる改善度')
    plt.grid(True, alpha=0.3)
    plt.savefig('plots/model_improvement.png')
    plt.close()
    
    print(f"平均改善度: {mean_improvement:.4f}")
    print(f"改善された分子の割合: {np.sum(improvements > 0) / len(improvements):.2%}")
    
    return general_scores, specialized_scores, mean_improvement

def evaluate_specialized_model():
    """訓練済み特化型モデルを評価"""
    # MSPファイルを解析
    print("MSPファイルを解析中...")
    msp_data = parse_msp_file(MSP_FILE_PATH)
    
    # CSVから類似分子情報を読み込み
    similar_mol_ids = []
    similarities = []
    
    with open('results/similar_molecules.csv', 'r') as f:
        next(f)  # ヘッダーをスキップ
        for line in f:
            parts = line.strip().split(',')
            mol_id = int(parts[0])
            similarity = float(parts[1])
            similar_mol_ids.append(mol_id)
            similarities.append(similarity)
    
    # データセットの作成
    dataset = MoleculeGraphDataset(similar_mol_ids, MOL_FILES_PATH, msp_data, augment=False)
    
    # データを分割（検証:テスト = 20:80）
    val_size = int(0.2 * len(dataset))
    test_size = len(dataset) - val_size
    val_dataset, test_dataset = random_split(dataset, [val_size, test_size])
    
    # サンプルデータから特徴量の次元を取得
    sample_data = dataset[0][0]
    node_features = sample_data.x.size(1)
    edge_features = sample_data.edge_attr.size(1)
    
    # デバイスの設定
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 特化型モデルをロード
    model = HybridGNNModel(node_features, edge_features, HIDDEN_CHANNELS, MAX_MZ).to(device)
    model.load_state_dict(torch.load('models/best_specialized_model.pth', map_location=device))
    
    # モデル評価
    _, test_cosine_sim, y_true, y_pred = evaluate_model(model, test_dataset, device)
    
    # スペクトル予測を可視化
    visualize_spectrum_predictions(y_true, y_pred)
    
    # データローダーの作成
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)
    
    # 埋め込みを抽出
    embeddings, mol_ids = extract_embeddings(model, dataloader, device)
    
    # 分子クラスターを可視化
    visualize_molecule_clusters(embeddings, mol_ids, similarities)
    
    return test_cosine_sim
```

## 10. メイン実行コード - 類似分子選択と特化型モデルトレーニング (続き)

```python
def main():
    # MSPファイルを解析
    print("MSPファイルを解析中...")
    msp_data = parse_msp_file(MSP_FILE_PATH)
    print(f"MSPファイルから{len(msp_data)}個の化合物データを読み込みました")
    
    # ターゲット分子の設定
    target_smiles = "CC1=C[C@]2([H])[C@@](C(C)(C)OC3=C2C(O)=CC(CCCCC)=C3)([H])CC1"
    
    # 類似分子を検索
    similar_mol_ids, similarities = find_similar_molecules(
        target_smiles, MOL_FILES_PATH, msp_data, n_similar=1000
    )
    
    # 類似度分布の可視化
    visualize_similarity_distribution(similarities)
    
    # 代表的な分子の可視化
    visualize_representative_molecules(similar_mol_ids, similarities, MOL_FILES_PATH)
    
    # 類似分子情報をCSVに保存
    with open('results/similar_molecules.csv', 'w') as f:
        f.write("Molecule_ID,Similarity\n")
        for mol_id, sim in zip(similar_mol_ids, similarities):
            f.write(f"{mol_id},{sim:.6f}\n")
    
    print("類似分子のリストをresults/similar_molecules.csvに保存しました")
    
    # データセット作成
    print("特化型データセット作成中...")
    dataset = MoleculeGraphDataset(similar_mol_ids, MOL_FILES_PATH, msp_data, augment=True)
    print(f"有効な分子数: {len(dataset)}個")
    
    # データを分割（訓練:検証 = 80:20）
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    print(f"訓練データ: {len(train_dataset)}個")
    print(f"検証データ: {len(val_dataset)}個")
    
    # データローダーの作成
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)
    
    # サンプルデータから特徴量の次元を取得
    sample_data = dataset[0][0]
    node_features = sample_data.x.size(1)
    edge_features = sample_data.edge_attr.size(1)
    
    print(f"ノード特徴量次元: {node_features}")
    print(f"エッジ特徴量次元: {edge_features}")
    
    # デバイスの設定
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"使用デバイス: {device}")
    
    # モデルの初期化
    model = HybridGNNModel(node_features, edge_features, HIDDEN_CHANNELS, MAX_MZ).to(device)
    
    # 訓練済みの汎用モデルがある場合は重みをロード（転移学習）
    try:
        model.load_state_dict(torch.load('models/best_gcn_ms_model.pth', map_location=device))
        print("汎用モデルの重みをロードしました - 転移学習を行います")
    except:
        print("汎用モデルが見つからないため、ゼロから学習します")
    
    # 損失関数とオプティマイザーの設定
    criterion = combined_loss
    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)
    
    # 学習率スケジューラー
    steps_per_epoch = len(train_loader)
    scheduler = OneCycleLR(
        optimizer,
        max_lr=0.003,
        steps_per_epoch=steps_per_epoch,
        epochs=NUM_EPOCHS,
        pct_start=0.1,  # 10%の期間でウォームアップ
        div_factor=25.0,  # 初期学習率 = max_lr/div_factor
        final_div_factor=10000.0  # 最終学習率 = max_lr/final_div_factor
    )
    
    # モデルトレーニング
    print("特化型モデルのトレーニングを開始します...")
    train_losses, val_losses, val_cosine_similarities = train_model(
        model, train_loader, val_loader, criterion, optimizer, scheduler, NUM_EPOCHS, device
    )
    
    # 学習曲線を可視化
    plt.figure(figsize=(15, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label='訓練損失')
    plt.plot(val_losses, label='検証損失')
    plt.xlabel('エポック')
    plt.ylabel('損失')
    plt.legend()
    plt.title('損失曲線 - 特化型モデル')
    
    plt.subplot(1, 2, 2)
    plt.plot(val_cosine_similarities, label='検証コサイン類似度')
    plt.xlabel('エポック')
    plt.ylabel('コサイン類似度')
    plt.legend()
    plt.title('コサイン類似度 - 特化型モデル')
    
    plt.tight_layout()
    plt.savefig('plots/specialized_model_learning_curves.png')
    plt.close()
    
    # 学習履歴の保存
    history = {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'val_cosine_similarities': val_cosine_similarities
    }
    
    with open('results/training_history.json', 'w') as f:
        json.dump({k: [float(val) for val in v] for k, v in history.items()}, f, indent=4)
    
    print("トレーニング完了！")
    print(f"最良の検証コサイン類似度: {max(val_cosine_similarities):.4f}")
    
    # 汎用モデルとの比較（汎用モデルが存在する場合）
    try:
        general_scores, specialized_scores, mean_improvement = compare_general_vs_specialized(
            similar_mol_ids, MOL_FILES_PATH, msp_data
        )
        print(f"汎用モデルからの平均改善度: {mean_improvement:.4f}")
    except Exception as e:
        print(f"汎用モデルとの比較中にエラーが発生しました: {str(e)}")
    
    return model, similar_mol_ids, similarities
```

## 11. モデル評価の実行コード

```python
def run_evaluation():
    """特化型モデルの評価と可視化を実行する"""
    # MSPファイルの解析
    print("MSPファイルを解析中...")
    msp_data = parse_msp_file(MSP_FILE_PATH)
    
    # 保存済みの類似分子情報を読み込む
    try:
        similar_mol_ids = []
        similarities = []
        
        with open('results/similar_molecules.csv', 'r') as f:
            next(f)  # ヘッダーをスキップ
            for line in f:
                parts = line.strip().split(',')
                mol_id = int(parts[0])
                similarity = float(parts[1])
                similar_mol_ids.append(mol_id)
                similarities.append(similarity)
        
        print(f"{len(similar_mol_ids)}個の類似分子情報を読み込みました")
    except Exception as e:
        print(f"類似分子情報の読み込みに失敗しました: {str(e)}")
        return
    
    # データセットの作成
    dataset = MoleculeGraphDataset(similar_mol_ids, MOL_FILES_PATH, msp_data, augment=False)
    
    # データを分割
    test_size = int(0.2 * len(dataset))
    train_size = len(dataset) - test_size
    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])
    
    # サンプルデータから特徴量の次元を取得
    sample_data = dataset[0][0]
    node_features = sample_data.x.size(1)
    edge_features = sample_data.edge_attr.size(1)
    
    # デバイスの設定
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"使用デバイス: {device}")
    
    # 特化型モデルをロード
    try:
        model = HybridGNNModel(node_features, edge_features, HIDDEN_CHANNELS, MAX_MZ).to(device)
        model.load_state_dict(torch.load('models/best_specialized_model.pth', map_location=device))
        print("特化型モデルをロードしました")
    except Exception as e:
        print(f"モデルのロードに失敗しました: {str(e)}")
        return
    
    # モデル評価
    print("モデル評価中...")
    test_loss, test_cosine_sim, y_true, y_pred = evaluate_model(model, test_dataset, device)
    
    # スペクトル予測を可視化
    print("予測スペクトルを可視化中...")
    visualize_spectrum_predictions(y_true, y_pred)
    
    # 埋め込みの抽出と可視化
    print("埋め込み特徴量を抽出中...")
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)
    embeddings, mol_ids = extract_embeddings(model, dataloader, device)
    
    print("分子クラスターを可視化中...")
    visualize_molecule_clusters(embeddings, mol_ids, similarities)
    
    # 評価結果をJSONに保存
    result = {
        'test_loss': float(test_loss),
        'test_cosine_similarity': float(test_cosine_sim),
        'embedding_dimension': embeddings.shape[1],
        'num_molecules': len(mol_ids)
    }
    
    with open('results/evaluation_results.json', 'w') as f:
        json.dump(result, f, indent=4)
    
    print(f"評価完了 - テストコサイン類似度: {test_cosine_sim:.4f}")
    
    return test_cosine_sim
```

## 12. 完全なパイプライン実行コード

```python
def run_complete_pipeline():
    """GraphSpecAIの完全なパイプラインを実行する"""
    # 1. MSPファイルの解析
    print("1. MSPファイルを解析中...")
    msp_data = parse_msp_file(MSP_FILE_PATH)
    print(f"  {len(msp_data)}個の化合物データを読み込みました")
    
    # 2. ターゲット分子の設定
    target_smiles = "CC1=C[C@]2([H])[C@@](C(C)(C)OC3=C2C(O)=CC(CCCCC)=C3)([H])CC1"
    print(f"2. ターゲット分子: {target_smiles}")
    
    # 3. 構造的に類似した分子を検索
    print("3. 類似分子の検索中...")
    similar_mol_ids, similarities = find_similar_molecules(
        target_smiles, MOL_FILES_PATH, msp_data, n_similar=1000
    )
    
    # 類似度分布の可視化
    visualize_similarity_distribution(similarities)
    
    # 代表的な分子の可視化
    visualize_representative_molecules(similar_mol_ids, similarities, MOL_FILES_PATH)
    
    # 4. 特化型モデルのトレーニング
    print("4. 特化型モデルのトレーニング中...")
    
    # 4.1 データセット作成
    dataset = MoleculeGraphDataset(similar_mol_ids, MOL_FILES_PATH, msp_data, augment=True)
    
    # 4.2 データを分割
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])
    
    # 4.3 データローダーの作成
    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)
    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)
    
    # 4.4 特徴量次元の取得
    sample_data = dataset[0][0]
    node_features = sample_data.x.size(1)
    edge_features = sample_data.edge_attr.size(1)
    
    # 4.5 デバイスの設定
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 4.6 モデルの初期化
    model = HybridGNNModel(node_features, edge_features, HIDDEN_CHANNELS, MAX_MZ).to(device)
    
    # 4.7 汎用モデルの重みをロード（転移学習）
    try:
        model.load_state_dict(torch.load('models/best_gcn_ms_model.pth', map_location=device))
        print("  汎用モデルの重みをロードしました - 転移学習を行います")
    except:
        print("  汎用モデルが見つからないため、ゼロから学習します")
    
    # 4.8 損失関数とオプティマイザーの設定
    criterion = combined_loss
    optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)
    
    # 4.9 学習率スケジューラー
    steps_per_epoch = len(train_loader)
    scheduler = OneCycleLR(
        optimizer,
        max_lr=0.003,
        steps_per_epoch=steps_per_epoch,
        epochs=NUM_EPOCHS,
        pct_start=0.1,
        div_factor=25.0,
        final_div_factor=10000.0
    )
    
    # 4.10 モデルトレーニング
    train_losses, val_losses, val_cosine_similarities = train_model(
        model, train_loader, val_loader, criterion, optimizer, scheduler, NUM_EPOCHS, device
    )
    
    # 4.11 学習履歴の保存
    history = {
        'train_losses': train_losses,
        'val_losses': val_losses,
        'val_cosine_similarities': val_cosine_similarities
    }
    
    with open('results/training_history.json', 'w') as f:
        json.dump({k: [float(val) for val in v] for k, v in history.items()}, f, indent=4)
    
    # 5. モデル評価
    print("5. モデル評価中...")
    
    # 5.1 埋め込みの抽出と可視化
    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)
    embeddings, mol_ids = extract_embeddings(model, dataloader, device)
    visualize_molecule_clusters(embeddings, mol_ids, similarities)
    
    # 5.2 汎用モデルと特化型モデルの比較
    try:
        general_scores, specialized_scores, mean_improvement = compare_general_vs_specialized(
            similar_mol_ids, MOL_FILES_PATH, msp_data
        )
        print(f"  汎用モデルからの改善度: {mean_improvement:.4f}")
    except:
        print("  汎用モデルが見つからないため、比較をスキップします")
    
    print("パイプライン実行完了!")
    
    return model, similar_mol_ids, similarities
```

## 13. 最終的な実行と結果の表示

```python
if __name__ == "__main__":
    # フルパイプラインの実行
    model, similar_mol_ids, similarities = main()
    
    # 最終結果を表示
    print("\n=== GraphSpecAI パイプライン実行結果 ===")
    print(f"ターゲット分子: CC1=C[C@]2([H])[C@@](C(C)(C)OC3=C2C(O)=CC(CCCCC)=C3)([H])CC1")
    print(f"類似分子数: {len(similar_mol_ids)}")
    print(f"類似度範囲: {min(similarities):.4f} - {max(similarities):.4f}")
    
    try:
        with open('results/training_history.json', 'r') as f:
            history = json.load(f)
        
        best_cosine = max(history['val_cosine_similarities'])
        print(f"特化型モデルの最高コサイン類似度: {best_cosine:.4f}")
    except:
        pass
    
    print("\n各種ファイルの出力先:")
    print("- 学習済みモデル: models/best_specialized_model.pth")
    print("- 類似分子情報: results/similar_molecules.csv")
    print("- 学習履歴: results/training_history.json")
    print("- 可視化結果: plots/")
```

## 14. まとめと次のステップ

このノートブックでは、GraphSpecAI特化型モデルのパイプラインを実装しました。主な機能は以下の通りです：

1. **分子クラスタリング**: ターゲット分子に構造的に類似した分子を識別
2. **特化型モデルのトレーニング**: 類似分子に特化したGNNモデルを構築
3. **モデル評価と可視化**: 特化型モデルの性能を評価し、結果を可視化
4. **モデル比較**: 汎用モデルと特化型モデルの性能比較

次のステップとして考えられること：

- **ハイパーパラメータチューニング**: モデルの性能をさらに向上させるためのチューニング
- **複数モデルのアンサンブル**: 複数の特化型モデルを組み合わせたアンサンブル学習
- **活性学習**: 予測精度を向上させるための追加実験データの選定
- **特徴工学の改善**: 質量分析に特化した特徴量の追加
- **説明可能AI技術の統合**: 予測結果の解釈可能性の向上

このパイプラインは、特定の分子ファミリーに特化したマススペクトル予測を行いたい場合や、限られたデータで高精度なモデルを構築したい場合に有効です。